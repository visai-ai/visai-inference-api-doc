<!doctype html>
<html lang="en" dir="ltr" class="plugin-openapi plugin-id-inference-api">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.1">
<title data-rh="true">Introduction | VISAI API Documentation</title><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://visai-ai.github.io/visai-inference-api-doc/inference-api/introduction-3"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:image" content="https://visai-ai.github.io/visai-inference-api-doc/img/visai_logo_bg.png"><meta data-rh="true" property="og:title" content="Introduction | VISAI API Documentation"><meta data-rh="true" name="description" content="Speech Segmentation, also known as Voice activity detection (VAD), is the detection of the human speech or non-speech. The speech segmentation is widely used to facilitate in speech processing such as Automatic Speech Recognition (ASR), and Speech Emotion Recognition (SER).

# Base Model - VISAI Speech Segmentaion

We used a model from NeMo¹ and fine-tune to support Thai language. The model was trained with a speech dataset from Thai SER², and background datasets from MUSAN³ and ChMusic⁴. The evaluation set was split from the same source as training data and rebalanced to have the same number of segments in each of the classes. If background noise is very loud, the model will fail to detect some words.

# Authentication
Speech Segmentation requires API key for API request. Go to [API Key Management](https://visai.ai/api-key-management) to create and get your API Key.
  - x-api-key
"><meta data-rh="true" property="og:description" content="Speech Segmentation, also known as Voice activity detection (VAD), is the detection of the human speech or non-speech. The speech segmentation is widely used to facilitate in speech processing such as Automatic Speech Recognition (ASR), and Speech Emotion Recognition (SER).

# Base Model - VISAI Speech Segmentaion

We used a model from NeMo¹ and fine-tune to support Thai language. The model was trained with a speech dataset from Thai SER², and background datasets from MUSAN³ and ChMusic⁴. The evaluation set was split from the same source as training data and rebalanced to have the same number of segments in each of the classes. If background noise is very loud, the model will fail to detect some words.

# Authentication
Speech Segmentation requires API key for API request. Go to [API Key Management](https://visai.ai/api-key-management) to create and get your API Key.
  - x-api-key
"><link data-rh="true" rel="icon" href="/visai-inference-api-doc/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://visai-ai.github.io/visai-inference-api-doc/inference-api/introduction-3"><link data-rh="true" rel="alternate" href="https://visai-ai.github.io/visai-inference-api-doc/inference-api/introduction-3" hreflang="en"><link data-rh="true" rel="alternate" href="https://visai-ai.github.io/visai-inference-api-doc/inference-api/introduction-3" hreflang="x-default"><link rel="stylesheet" href="/visai-inference-api-doc/assets/css/styles.65a1d1bb.css">
<link rel="preload" href="/visai-inference-api-doc/assets/js/runtime~main.a8f487aa.js" as="script">
<link rel="preload" href="/visai-inference-api-doc/assets/js/main.fdf14ef8.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"dark")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_fXgn">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/visai-inference-api-doc/"><div class="navbar__logo"><img src="/visai-inference-api-doc/img/visai.png" alt="VISAI" class="themedImage_ToTc themedImage--light_HNdA"><img src="/visai-inference-api-doc/img/visai.png" alt="VISAI" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">API Documentation</b></a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">API</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/visai-inference-api-doc/inference-api/machine-translation-base-model">Machine Translation</a></li><li><a class="dropdown__link" href="/visai-inference-api-doc/inference-api/ocr-general-document-base-model">OCR General Document</a></li><li><a class="dropdown__link" href="/visai-inference-api-doc/inference-api/sentiment-analysis-base-model">Sentiment Anlaysis</a></li><li><a class="dropdown__link" href="/visai-inference-api-doc/inference-api/speech-segmentation-base-model">Speech Segmentation</a></li><li><a class="dropdown__link" href="/visai-inference-api-doc/inference-api/speech-to-text-base-model">Speech to Text</a></li><li><a class="dropdown__link" href="/visai-inference-api-doc/inference-api/word-tokenization-base-model">Word Tokenization</a></li></ul></div></div><div class="navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper mainWrapper_z2l0 api-wrapper"><div class="apiPage_KQrU"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><aside class="apiSidebarContainer_Korj"><div class="sidebar_njMd"><nav class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/visai-inference-api-doc/inference-api/introduction">Machine Translation</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/visai-inference-api-doc/inference-api/introduction-1">OCR General Document</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/visai-inference-api-doc/inference-api/introduction-2">Sentiment Analysis</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/visai-inference-api-doc/inference-api/introduction-3">Speech Segmentation</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/visai-inference-api-doc/inference-api/introduction-3">Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/visai-inference-api-doc/inference-api/speech-segmentation-base-model">Base Model API</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/visai-inference-api-doc/inference-api/introduction-4">Speech to Text</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/visai-inference-api-doc/inference-api/introduction-5">Word Tokenization</a></div></li></ul></nav></div></aside><main class="apiMainContainer_L2xG"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col"><div class="apiItemContainer_gBt2"><article><div class="theme-api-markdown markdown"><span class="theme-doc-version-badge badge badge--secondary">Version: 1.0.0</span><h1>Speech Segmentation</h1><p>Speech Segmentation, also known as Voice activity detection (VAD), is the detection of the human speech or non-speech. The speech segmentation is widely used to facilitate in speech processing such as Automatic Speech Recognition (ASR), and Speech Emotion Recognition (SER).</p><h1>Base Model - VISAI Speech Segmentaion</h1><p>We used a model from NeMo¹ and fine-tune to support Thai language. The model was trained with a speech dataset from Thai SER², and background datasets from MUSAN³ and ChMusic⁴. The evaluation set was split from the same source as training data and rebalanced to have the same number of segments in each of the classes. If background noise is very loud, the model will fail to detect some words.</p><h1>Authentication</h1><p>Speech Segmentation requires API key for API request. Go to <a href="https://visai.ai/api-key-management" target="_blank" rel="noopener noreferrer">API Key Management</a> to create and get your API Key.</p><ul><li>x-api-key</li></ul></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/visai-inference-api-doc/inference-api/sentiment-analysis-your-model"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Sentiment Analysis Your-model</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/visai-inference-api-doc/inference-api/speech-segmentation-base-model"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Speech Segmentation Base-model</div></a></nav></div></div><div class="col col--3"></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="margin-bottom--sm"><a href="https://visai.ai/" rel="noopener noreferrer" class="footerLogoLink_BH7S"><img src="/visai-inference-api-doc/img/visai.png" alt="Deploys by Netlify" class="themedImage_ToTc themedImage--light_HNdA footer__logo" width="160" height="40"><img src="/visai-inference-api-doc/img/visai.png" alt="Deploys by Netlify" class="themedImage_ToTc themedImage--dark_i4oU footer__logo" width="160" height="40"></a></div><div class="footer__copyright">Copyright © 2022 VISAI. All rights reserved.</div></div></div></footer></div>
<script src="/visai-inference-api-doc/assets/js/runtime~main.a8f487aa.js"></script>
<script src="/visai-inference-api-doc/assets/js/main.fdf14ef8.js"></script>
</body>
</html>