openapi: 3.0.3
servers:
  - url: https://infer.visai.ai/v1/inference-servers/
    description: Default server
info:
  title: Speech to Text
  version: 1.0.0
  description: |
    **Speech to Text** or **Automatic Speech Recognition (ASR)** is one of the machine learning tasks that aim to predict the corresponding transcription from a given audio input. ASR can be beneficial for several use cases, such as online course transcription, movie subtitle, call center transcription, and so forth.

    # Base Model - Thai Speech to Text
    > **Provider: Gowajee**

    We utilized a model from our partner, [Gowajee](https://www.gowajee.ai/). The model is trained by using over 1,000 hours of annotated data collected online by our partner from various sources. This model can perform in general topics but specializes in call center. The model could be worsened if audio contains code switching, low-quality speech, and overlapping speech data. The model's performance was evaluated on around 60 hours of speech data, which was collected from the same source as the training data.

    # Authentication
    Speech to Text requires API key for API request. Go to [API Key Management](https://web-dev.visai.ai/api-key-management) to create and get your API Key.
      - x-api-key
tags:
  - name: base-model
    description: Base model inference API
    x-displayName: Base Model API
  - name: your-model
    description: Your model inference API
    x-displayName: Your Model API
x-tagGroups:
  - name: General
    tags:
      - base-model
      - your-model
paths:
  /base/infer-8ea77bf0:
    post:
      tags:
        - base-model
      summary: speech to text base-model
      description: "Process human speech into readable text"
      operationId: https://infer.visai.ai/v1/inference-servers
      responses:
        "200":
          description: Return list of transcribed text that corresponds to speech detected in audio.
          content:
            application/json:
              schema:
                type: object
                properties:
                  results:
                    type: array
                    items:
                      type: object
                      properties:
                        filename:
                          type: string
                          description: Name of audio file
                        duration:
                          type: string
                          description: Total time(sec) of audio file
                        predictions:
                          type: array
                          description: List of outputs corresponds to speech detected in audio file
                          items:
                            type: object
                            properties:
                              transcript:
                                type: string
                                description: Transcribed text
                              start_time:
                                type: string
                                description: Start time(sec) of transcribed text
                              end_time:
                                type: string
                                description: End time(sec) of transcribed text
                              speaking_rate:
                                type: string
                                description: Speaking rate of each transcription // optional
                              word_timestamps:
                                type: array
                                description: List of time offsets of each word // optional
                                items:
                                  type: object
                                  properties:
                                    word:
                                      type: string
                                      description: Transcribed word // optional
                                    start_time:
                                      type: string
                                      description: Start time(sec) offset of word // optional
                                    end_time:
                                      type: string
                                      description: End time(sec) offset of word // optional
      requestBody:
        content:
          multipart/form-data:
            schema:
              type: object
              properties:
                files:
                  type: string
                  format: binary
                  description: .wav speech file
                word_timestamps:
                  type: string
                  description: word_timestamps //optional
                speaking_rate:
                  type: string
                  description: speaking_rate //optional
                decoder_type:
                  type: string
                  description: decoder_type //optional
                word_list:
                  type: string
                  description: word_list //optional
              required:
                - files
      # requestBody:
      #   content:
      #     application/octet-stream:
      #       schema:
      #         type: string
      #         format: binary
      parameters:
        - schema:
            type: string
          in: header
          name: x-api-key
          description: Your API key
          required: true
    parameters: []
  "/your/{endpoint}":
    post:
      tags:
        - your-model
      summary: speech to text your-model
      description: "Process human speech into readable text"
      operationId: https://infer.visai.ai/v1/inference-servers
      parameters:
        - name: x-api-key
          in: header
          required: true
          schema:
            type: string
        - name: endpoint
          in: path
          description: Your model endpoint
          required: true
          schema:
            type: string
      responses:
        "200":
          description: Return list of transcribed text that corresponds to speech detected in audio.
          content:
            application/json:
              schema:
                type: object
                properties:
                  results:
                    type: array
                    items:
                      type: object
                      properties:
                        filename:
                          type: string
                          description: Name of audio file
                        duration:
                          type: string
                          description: Total time(sec) of audio file
                        predictions:
                          type: array
                          description: List of outputs corresponds to speech detected in audio file
                          items:
                            type: object
                            properties:
                              transcript:
                                type: string
                                description: Transcribed text
                              start_time:
                                type: string
                                description: Start time(sec) of transcribed text
                              end_time:
                                type: string
                                description: End time(sec) of transcribed text
                              speaking_rate:
                                type: string
                                description: Speaking rate of each transcription // optional
                              word_timestamps:
                                type: array
                                description: List of time offsets of each word // optional
                                items:
                                  type: object
                                  properties:
                                    word:
                                      type: string
                                      description: Transcribed word // optional
                                    start_time:
                                      type: string
                                      description: Start time(sec) offset of word // optional
                                    end_time:
                                      type: string
                                      description: End time(sec) offset of word // optional
      requestBody:
        content:
          multipart/form-data:
            schema:
              type: object
              properties:
                files:
                  type: string
                  format: binary
                  description: .wav speech file
                word_timestamps:
                  type: string
                speaking_rate:
                  type: string
                decoder_type:
                  type: string
                word_list:
                  type: string
              required:
                - files
      # requestBody:
      #   content:
      #     application/octet-stream:
      #       schema:
      #         type: string
      #         format: binary
    parameters: []
