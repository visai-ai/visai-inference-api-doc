"use strict";(self.webpackChunkvisai_inference_api_doc=self.webpackChunkvisai_inference_api_doc||[]).push([[190],{3905:(e,t,n)=>{n.d(t,{Zo:()=>l,kt:()=>h});var o=n(67294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function c(e,t){if(null==e)return{};var n,o,a=function(e,t){if(null==e)return{};var n,o,a={},i=Object.keys(e);for(o=0;o<i.length;o++)n=i[o],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(o=0;o<i.length;o++)n=i[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=o.createContext({}),p=function(e){var t=o.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},l=function(e){var t=p(e.components);return o.createElement(s.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},d=o.forwardRef((function(e,t){var n=e.components,a=e.mdxType,i=e.originalType,s=e.parentName,l=c(e,["components","mdxType","originalType","parentName"]),d=p(n),h=a,m=d["".concat(s,".").concat(h)]||d[h]||u[h]||i;return n?o.createElement(m,r(r({ref:t},l),{},{components:n})):o.createElement(m,r({ref:t},l))}));function h(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=n.length,r=new Array(i);r[0]=d;var c={};for(var s in t)hasOwnProperty.call(t,s)&&(c[s]=t[s]);c.originalType=e,c.mdxType="string"==typeof e?e:a,r[1]=c;for(var p=2;p<i;p++)r[p]=n[p];return o.createElement.apply(null,r)}return o.createElement.apply(null,n)}d.displayName="MDXCreateElement"},59338:(e,t,n)=>{n.r(t),n.d(t,{contentTitle:()=>r,default:()=>l,frontMatter:()=>i,metadata:()=>c,toc:()=>s});var o=n(87462),a=(n(67294),n(3905));const i={},r=void 0,c={type:"info",id:"introduction-3",unversionedId:"introduction-3",title:"Introduction",description:"**Speech segmentation**, also known as Voice activity detection (VAD), is the detection of the human speech or non-speech. The speech segmentation is widely used to facilitate in speech processing such as Automatic Speech Recognition (ASR), and Speech Emotion Recognition (SER).\n\n# Base Model - VISAI Speech Segmentaion\n> **Provider: Gowajee**\n\nWe utilized a model from our partner, [Gowajee](https://www.gowajee.ai/). The model is trained by using over 1,000 hours of annotated data collected online by our partner from various sources. This model can perform in general topics but specializes in call center. The model could be worsened if audio contains code switching, low-quality speech, and overlapping speech data. The model's performance was evaluated on around 60 hours of speech data, which was collected from the same source as the training data.\n\n# Authentication\nSpeech to Text requires API key for API request. Go to [API Key Management](https://visai.ai/api-key-management) to create and get your API Key.\n  - x-api-key\n",slug:"/introduction-3",frontMatter:{},info:{title:"Speech to Text",version:"1.0.0",description:"**Speech segmentation**, also known as Voice activity detection (VAD), is the detection of the human speech or non-speech. The speech segmentation is widely used to facilitate in speech processing such as Automatic Speech Recognition (ASR), and Speech Emotion Recognition (SER).\n\n# Base Model - VISAI Speech Segmentaion\n> **Provider: Gowajee**\n\nWe utilized a model from our partner, [Gowajee](https://www.gowajee.ai/). The model is trained by using over 1,000 hours of annotated data collected online by our partner from various sources. This model can perform in general topics but specializes in call center. The model could be worsened if audio contains code switching, low-quality speech, and overlapping speech data. The model's performance was evaluated on around 60 hours of speech data, which was collected from the same source as the training data.\n\n# Authentication\nSpeech to Text requires API key for API request. Go to [API Key Management](https://visai.ai/api-key-management) to create and get your API Key.\n  - x-api-key\n"},source:"@site/api/openapi-speech-to-text.yaml",sourceDirName:".",permalink:"/visai-inference-api-doc/inference-api/introduction-3",previous:{title:"Sentiment Analysis Your-model",permalink:"/visai-inference-api-doc/inference-api/sentiment-analysis-your-model"},next:{title:"Speech to Text Base-model",permalink:"/visai-inference-api-doc/inference-api/speech-to-text-base-model"}},s=[],p={toc:s};function l(e){let{components:t,...n}=e;return(0,a.kt)("wrapper",(0,o.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("span",{className:"theme-doc-version-badge badge badge--secondary"},"Version: 1.0.0"),(0,a.kt)("h1",{id:"speech-to-text"},"Speech to Text"),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Speech segmentation"),", also known as Voice activity detection (VAD), is the detection of the human speech or non-speech. The speech segmentation is widely used to facilitate in speech processing such as Automatic Speech Recognition (ASR), and Speech Emotion Recognition (SER)."),(0,a.kt)("h1",{id:"base-model---visai-speech-segmentaion"},"Base Model - VISAI Speech Segmentaion"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("strong",{parentName:"p"},"Provider: Gowajee"))),(0,a.kt)("p",null,"We utilized a model from our partner, ",(0,a.kt)("a",{parentName:"p",href:"https://www.gowajee.ai/"},"Gowajee"),". The model is trained by using over 1,000 hours of annotated data collected online by our partner from various sources. This model can perform in general topics but specializes in call center. The model could be worsened if audio contains code switching, low-quality speech, and overlapping speech data. The model's performance was evaluated on around 60 hours of speech data, which was collected from the same source as the training data."),(0,a.kt)("h1",{id:"authentication"},"Authentication"),(0,a.kt)("p",null,"Speech to Text requires API key for API request. Go to ",(0,a.kt)("a",{parentName:"p",href:"https://visai.ai/api-key-management"},"API Key Management")," to create and get your API Key."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"x-api-key")))}l.isMDXComponent=!0}}]);