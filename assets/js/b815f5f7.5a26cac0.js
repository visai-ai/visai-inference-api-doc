"use strict";(self.webpackChunkvisai_inference_api_doc=self.webpackChunkvisai_inference_api_doc||[]).push([[887],{3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>f});var r=n(67294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,i=function(e,t){if(null==e)return{};var n,r,i={},a=Object.keys(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var c=r.createContext({}),s=function(e){var t=r.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},p=function(e){var t=s(e.components);return r.createElement(c.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},u=r.forwardRef((function(e,t){var n=e.components,i=e.mdxType,a=e.originalType,c=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),u=s(n),f=i,m=u["".concat(c,".").concat(f)]||u[f]||d[f]||a;return n?r.createElement(m,o(o({ref:t},p),{},{components:n})):r.createElement(m,o({ref:t},p))}));function f(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var a=n.length,o=new Array(a);o[0]=u;var l={};for(var c in t)hasOwnProperty.call(t,c)&&(l[c]=t[c]);l.originalType=e,l.mdxType="string"==typeof e?e:i,o[1]=l;for(var s=2;s<a;s++)o[s]=n[s];return r.createElement.apply(null,o)}return r.createElement.apply(null,n)}u.displayName="MDXCreateElement"},31462:(e,t,n)=>{n.r(t),n.d(t,{contentTitle:()=>o,default:()=>p,frontMatter:()=>a,metadata:()=>l,toc:()=>c});var r=n(87462),i=(n(67294),n(3905));const a={},o="Optical Character Recognition Inference API",l={type:"api",id:"optical-character-recognition-inference-api",unversionedId:"optical-character-recognition-inference-api",title:"Optical Character Recognition Inference API",description:"",slug:"/optical-character-recognition-inference-api",frontMatter:{},api:{operationId:"post-ocr-inference",responses:{200:{description:"Return list of bounding box coordinates and text",content:{"application/json":{schema:{type:"array",items:{type:"object",properties:{image_size:{type:"array",description:"Page width size, page height, and page number (ex. [430, 405, 3])",items:{type:"integer"}},results:{type:"array",description:"List of the coordinates of the extracted text. These coordinates consist of 4 points representing the box, and each coordinates contains 2 numerical values representing X and Y coordinates of the text location inside an image.",items:{type:["array","string"],items:{}}},texts:{type:"string",description:"Full texts of each page"}}}},example:[{image_size:[430,705,3],results:[[[[116,22],[226,22],[226,74],[116,74]],"\u0e2a\u0e33\u0e40\u0e19\u0e32"],[[[42,136],[216,136],[216,188],[42,188]],"\u0e2a\u0e33\u0e40\u0e19\u0e32\u0e04\u0e39\u0e48\u0e09\u0e1a\u0e31\u0e1a"],[[[42,198],[248,198],[248,248],[42,248]],"\u0e1a\u0e31\u0e19\u0e17\u0e36\u0e01\u0e02\u0e49\u0e2d\u0e04\u0e27\u0e32\u0e21"],[[[104,324],[185,324],[185,361],[104,361]],"-"],[[[568,328],[626,328],[626,356],[568,356]],"-"]],texts:"\u0e2a\u0e33\u0e40\u0e19\u0e32 \u0e2a\u0e33\u0e40\u0e19\u0e32\u0e04\u0e39\u0e48\u0e09\u0e1a\u0e31\u0e1a \u0e1a\u0e31\u0e19\u0e17\u0e36\u0e01\u0e02\u0e49\u0e2d\u0e04\u0e27\u0e32\u0e21 - -"}]}}}},description:"Convert an image of text into a machine-readable text format. ",parameters:[{schema:{type:"string"},in:"header",name:"x-api-key",required:!0,description:"Your API Key"}],requestBody:{content:{"multipart/form-data":{schema:{type:"object",properties:{files:{description:"Document file (.docx, .pptx, .pdf, .png, and .jpeg)",type:"string",format:"binary"}}}}},description:"",required:!0},method:"post",path:"/predict",servers:[{url:"https://infer-dev.visai.ai/v1/inference-servers/",description:"Default server"},{url:"//petstore.swagger.io/sandbox",description:"Sandbox server"}],info:{title:"Optical Character Recognition",version:"1.0.0",description:"**OCR or Optical Image Recognition** is the process of extracting a textual information from an image. In other word, it's an image to text stored the result as a series of character or text that is encoded by a specific character encoding method such as UTF-8. Thus, this makes it easier and more accurate for a computer to perform some tasks on these texts. For example, conducting document search from PDF files using OCR and information retrieval.\n\nThe transcribed characters are encoded by a specific character encoding method such as UTF-8. This makes it easier and more accurate for a computer to perform some tasks on these texts. For example, conducting document search from PDF files using OCR and information retrieval.\n\n# Authentication\nOCR requires API key for API request. Go to [API Key Management](https://web-dev.visai.ai/api-key-management) to create and get your API Key.\n  - x-api-key\n"},postman:{name:"Optical Character Recognition Inference API",description:{content:"Convert an image of text into a machine-readable text format. ",type:"text/plain"},url:{path:["predict"],host:["{{baseUrl}}"],query:[],variable:[]},header:[{description:{content:"(Required) Your API Key",type:"text/plain"},key:"x-api-key",value:"<string>"},{key:"Content-Type",value:"multipart/form-data"}],method:"POST",body:{mode:"formdata",formdata:[{description:{content:"Document file (.docx, .pptx, .pdf, .png, and .jpeg)",type:"text/plain"},key:"files",value:"<binary>",type:"text"}]}}},source:"@site/api/openapi-ocr.yaml",sourceDirName:".",permalink:"/visai-inference-api-doc/inference-api/optical-character-recognition-inference-api",previous:{title:"Introduction",permalink:"/visai-inference-api-doc/inference-api/introduction"},next:{title:"Introduction",permalink:"/visai-inference-api-doc/inference-api/introduction-1"}},c=[],s={toc:c};function p(e){let{components:t,...n}=e;return(0,i.kt)("wrapper",(0,r.Z)({},s,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"optical-character-recognition-inference-api"},"Optical Character Recognition Inference API"),(0,i.kt)("p",null,"Convert an image of text into a machine-readable text format. "),(0,i.kt)("table",{style:{display:"table",width:"100%"}},(0,i.kt)("thead",null,(0,i.kt)("tr",null,(0,i.kt)("th",{style:{textAlign:"left"}},"Header Parameters"))),(0,i.kt)("tbody",null,(0,i.kt)("tr",null,(0,i.kt)("td",null,(0,i.kt)("code",null,"x-api-key"),(0,i.kt)("span",{style:{opacity:"0.6"}}," string"),(0,i.kt)("span",{style:{opacity:"0.6"}}," \u2014 "),(0,i.kt)("strong",{style:{fontSize:"var(--ifm-code-font-size)",color:"var(--openapi-required)"}}," REQUIRED"),(0,i.kt)("div",{style:{marginTop:"var(--ifm-table-cell-padding)"}},(0,i.kt)("p",null,"Your API Key")))))),(0,i.kt)("table",{style:{display:"table",width:"100%"}},(0,i.kt)("thead",null,(0,i.kt)("tr",null,(0,i.kt)("th",{style:{textAlign:"left"}},"Request Body ",(0,i.kt)("span",{style:{opacity:"0.6"}}," \u2014 "),(0,i.kt)("strong",{style:{fontSize:"var(--ifm-code-font-size)",color:"var(--openapi-required)"}}," REQUIRED"),(0,i.kt)("div",null)))),(0,i.kt)("tbody",null,(0,i.kt)("tr",null,(0,i.kt)("td",null,(0,i.kt)("code",null,"files"),(0,i.kt)("span",{style:{opacity:"0.6"}}," binary"),(0,i.kt)("div",{style:{marginTop:"var(--ifm-table-cell-padding)"}},(0,i.kt)("p",null,"Document file (.docx, .pptx, .pdf, .png, and .jpeg)")))))),(0,i.kt)("table",{style:{display:"table",width:"100%"}},(0,i.kt)("thead",null,(0,i.kt)("tr",null,(0,i.kt)("th",{style:{textAlign:"left"}},"Responses"))),(0,i.kt)("tbody",null,(0,i.kt)("tr",null,(0,i.kt)("td",null,(0,i.kt)("div",{style:{display:"flex"}},(0,i.kt)("div",{style:{marginRight:"var(--ifm-table-cell-padding)"}},(0,i.kt)("code",null,"200")),(0,i.kt)("div",null,(0,i.kt)("p",null,"Return list of bounding box coordinates and text"))),(0,i.kt)("div",null,(0,i.kt)("table",{style:{display:"table",width:"100%",marginTop:"var(--ifm-table-cell-padding)",marginBottom:"0px"}},(0,i.kt)("thead",null,(0,i.kt)("tr",null,(0,i.kt)("th",{style:{textAlign:"left"}},"Schema ",(0,i.kt)("div",null)))),(0,i.kt)("tbody",null,(0,i.kt)("tr",null,(0,i.kt)("td",null,(0,i.kt)("span",{style:{opacity:"0.6"}}," object[]"),(0,i.kt)("table",{style:{display:"table",width:"100%",marginTop:"var(--ifm-table-cell-padding)",marginBottom:"0px"}},(0,i.kt)("tbody",null,(0,i.kt)("tr",null,(0,i.kt)("td",null,(0,i.kt)("code",null,"image_size"),(0,i.kt)("span",{style:{opacity:"0.6"}}," integer[]"),(0,i.kt)("div",{style:{marginTop:"var(--ifm-table-cell-padding)"}},(0,i.kt)("p",null,"Page width size, page height, and page number (ex. ","[430, 405, 3]",")")))),(0,i.kt)("tr",null,(0,i.kt)("td",null,(0,i.kt)("code",null,"results"),(0,i.kt)("span",{style:{opacity:"0.6"}}," array,string[]"),(0,i.kt)("div",{style:{marginTop:"var(--ifm-table-cell-padding)"}},(0,i.kt)("p",null,"List of the coordinates of the extracted text. These coordinates consist of 4 points representing the box, and each coordinates contains 2 numerical values representing X and Y coordinates of the text location inside an image.")))),(0,i.kt)("tr",null,(0,i.kt)("td",null,(0,i.kt)("code",null,"texts"),(0,i.kt)("span",{style:{opacity:"0.6"}}," string"),(0,i.kt)("div",{style:{marginTop:"var(--ifm-table-cell-padding)"}},(0,i.kt)("p",null,"Full texts of each page"))))))))))))))))}p.isMDXComponent=!0}}]);