"use strict";(self.webpackChunkvisai_inference_api_doc=self.webpackChunkvisai_inference_api_doc||[]).push([[190],{3905:(e,t,n)=>{n.d(t,{Zo:()=>l,kt:()=>h});var o=n(67294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,o,a=function(e,t){if(null==e)return{};var n,o,a={},i=Object.keys(e);for(o=0;o<i.length;o++)n=i[o],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(o=0;o<i.length;o++)n=i[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var c=o.createContext({}),p=function(e){var t=o.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},l=function(e){var t=p(e.components);return o.createElement(c.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},d=o.forwardRef((function(e,t){var n=e.components,a=e.mdxType,i=e.originalType,c=e.parentName,l=s(e,["components","mdxType","originalType","parentName"]),d=p(n),h=a,m=d["".concat(c,".").concat(h)]||d[h]||u[h]||i;return n?o.createElement(m,r(r({ref:t},l),{},{components:n})):o.createElement(m,r({ref:t},l))}));function h(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=n.length,r=new Array(i);r[0]=d;var s={};for(var c in t)hasOwnProperty.call(t,c)&&(s[c]=t[c]);s.originalType=e,s.mdxType="string"==typeof e?e:a,r[1]=s;for(var p=2;p<i;p++)r[p]=n[p];return o.createElement.apply(null,r)}return o.createElement.apply(null,n)}d.displayName="MDXCreateElement"},59338:(e,t,n)=>{n.r(t),n.d(t,{contentTitle:()=>r,default:()=>l,frontMatter:()=>i,metadata:()=>s,toc:()=>c});var o=n(87462),a=(n(67294),n(3905));const i={},r=void 0,s={type:"info",id:"introduction-3",unversionedId:"introduction-3",title:"Introduction",description:"Speech Segmentation, also known as Voice activity detection (VAD), is the detection of the human speech or non-speech. The speech segmentation is widely used to facilitate in speech processing such as Automatic Speech Recognition (ASR), and Speech Emotion Recognition (SER).\n\n# Base Model - VISAI Speech Segmentaion\n\nWe used a model from NeMo\xb9 and fine-tune to support Thai language. The model was trained with a speech dataset from Thai SER\xb2, and background datasets from MUSAN\xb3 and ChMusic\u2074. The evaluation set was split from the same source as training data and rebalanced to have the same number of segments in each of the classes. If background noise is very loud, the model will fail to detect some words.\n\n# Authentication\nSpeech Segmentation requires API key for API request. Go to [VISAI Console - API Key](https://console.visai.ai/api-key) to create and get your API Key.\n  - X-API-Key\n",slug:"/introduction-3",frontMatter:{},info:{title:"Speech Segmentation",version:"1.0.0",description:"Speech Segmentation, also known as Voice activity detection (VAD), is the detection of the human speech or non-speech. The speech segmentation is widely used to facilitate in speech processing such as Automatic Speech Recognition (ASR), and Speech Emotion Recognition (SER).\n\n# Base Model - VISAI Speech Segmentaion\n\nWe used a model from NeMo\xb9 and fine-tune to support Thai language. The model was trained with a speech dataset from Thai SER\xb2, and background datasets from MUSAN\xb3 and ChMusic\u2074. The evaluation set was split from the same source as training data and rebalanced to have the same number of segments in each of the classes. If background noise is very loud, the model will fail to detect some words.\n\n# Authentication\nSpeech Segmentation requires API key for API request. Go to [VISAI Console - API Key](https://console.visai.ai/api-key) to create and get your API Key.\n  - X-API-Key\n"},source:"@site/api/openapi-speech-segmentation.yaml",sourceDirName:".",permalink:"/visai-inference-api-doc/inference-api/introduction-3",previous:{title:"Sentiment Analysis - Product Review",permalink:"/visai-inference-api-doc/inference-api/sentiment-analysis-product-review"},next:{title:"Speech Segmentation AI Marketplace",permalink:"/visai-inference-api-doc/inference-api/speech-segmentation-ai-marketplace"}},c=[],p={toc:c};function l(e){let{components:t,...n}=e;return(0,a.kt)("wrapper",(0,o.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("span",{className:"theme-doc-version-badge badge badge--secondary"},"Version: 1.0.0"),(0,a.kt)("h1",{id:"speech-segmentation"},"Speech Segmentation"),(0,a.kt)("p",null,"Speech Segmentation, also known as Voice activity detection (VAD), is the detection of the human speech or non-speech. The speech segmentation is widely used to facilitate in speech processing such as Automatic Speech Recognition (ASR), and Speech Emotion Recognition (SER)."),(0,a.kt)("h1",{id:"base-model---visai-speech-segmentaion"},"Base Model - VISAI Speech Segmentaion"),(0,a.kt)("p",null,"We used a model from NeMo\xb9 and fine-tune to support Thai language. The model was trained with a speech dataset from Thai SER\xb2, and background datasets from MUSAN\xb3 and ChMusic\u2074. The evaluation set was split from the same source as training data and rebalanced to have the same number of segments in each of the classes. If background noise is very loud, the model will fail to detect some words."),(0,a.kt)("h1",{id:"authentication"},"Authentication"),(0,a.kt)("p",null,"Speech Segmentation requires API key for API request. Go to ",(0,a.kt)("a",{parentName:"p",href:"https://console.visai.ai/api-key"},"VISAI Console - API Key")," to create and get your API Key."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"X-API-Key")))}l.isMDXComponent=!0}}]);